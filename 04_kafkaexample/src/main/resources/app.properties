####kafka producer setting
#kafka的服务端口
bootstrap.servers=mincdh:9092
#是否进行数据压缩，none, gzip, snappy, lz4
#compression.type=none
zookeeper.connect=mincdh:2181
#消息数据分区策略
#partitioner.class=com.liu.kafka.simple.MyPartitioner

#生产者发送消息后等待响应的最大时间，如果数据产生速度大于向broker发送的速度，producer会阻塞max.block.ms，超时则抛出异常
#request.timeout.ms=3000

#序列化类
key.serializer=org.apache.kafka.common.serialization.StringSerializer
value.serializer=org.apache.kafka.common.serialization.StringSerializer

#消息确认机制0，1，-1，all
acks=all

#生产者等待发送到kafka的消息队列占用内容的大小
#buffer.memory=50000

#消息发送失败的重试次数
#retries=3

#Producer可以将发往同一个Partition的数据做成一个Produce Request发送请求，即Batch批处理，以减少请求次数，
#该值即为每次批处理的大小
#batch.size=16384

#此项设置将会限制producer每次批量发送请求的数目，以防发出巨量的请求
#max.request.size

#保证exactly onece
#enable.idempotence=true

#在block前一个connection上允许最大未确认的requests数量。
#当设为1时，即是消息保证有序模式
#max.in.flight.requests.per.connection=1

#在第一次将数据发送到某topic时，需先fetch该topic的metadata，
#得知哪些服务器持有该topic的partition，该值为最长获取metadata时间
#metadata.fetch.timeout.ms=60000

####kafka consumer setting

#bootstrap.servers=mincdh:9092
#消费者的组编号
group.id=1

#一次消费的消息大小，如果数据量不够，这个请求会等待，直到数据量到达最小指标时，才会返回给消费者
fetch.min.bytes=1
fetch.max.bytes=52428800

#一次poll调用返回的最大消息数量
max.poll.records=2147483647

#poll时间的最大时间间隔
max.poll.interval.ms=300000

#手动提交offset
#enable.auto.commit=false

#自动提交offset的时间间隔
#auto.commit.interval.ms

#消息的反序列化类
key.deserializer=org.apache.kafka.common.serialization.StringDeserializer
value.deserializer=org.apache.kafka.common.serialization.StringDeserializer

#一次消费请求等待的时间
#request.timeout.ms=40000

#当offset丢失时如何恢复offset
#auto.offset.reset=latest

#每个partition一次fetch的最大大小
max.partition.fetch.bytes=1048576


#####kakfa server setting
#broker的唯一标识
#broker.id =0
#消息体的最大长度
#message.max.bytes =6525000
#broker处理网络请求的最大线程数量
#num.network.threads =4
#broker处理此片IO的线程数量
#num.io.threads =8
#后台线程数量
#background.threads =4
#等待IO线程处理的请求队列最大数量
#queued.max.requests =500
#消息数量回滚的时间
#log.roll.hours =24*7
#消息处理的策略
#log.cleanup.policy = delete
#消息保留的最大时间
#log.retention.hours=24
#数据保留的最大数量
#log.retention.bytes=-1
#文件大小的检查周期
#log.retention.check.interval.ms=5minutes
#是否开启消息清理
#log.cleaner.enable=false
#topic的分区数量
#num.partitions =1
#保留生产者的压缩
#compression.type=producer